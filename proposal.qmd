---
title: "**Variance All the Way Down:** Quantifying the Uncertainty Introduced at each Stage of an End-to-End RNA-Seq Analysis"
author: "Art Tay"
format:
  pdf:
     documentclass: article
     papersize: letter
     geometry:
         margin=1in
     include-in-header: header.tex
bibliography: references.bib
csl: american-statistical-association.csl
---

```{r setup, include=FALSE}
##Setup code
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

# Libraries
library(tidyverse)
library(tidymodels)
library(kableExtra)
library(MASS)

tidymodels_prefer()
```

# Abstract 

In the realm of RNA-Seq research, rigorous data preprocessing is a critical foundation for meaningful analysis. Despite its importance, this preprocessing involves numerous stages, each introducing potential sources of variance. While previous studies have examined the overall variance across entire RNA-Seq pipelines, [@arora2020variability] [@tong2020impact], [@vieth2019systematic], the impact of individual stages remains less understood. We propose a comprehensive investigation into the variance introduced at each stage of RNA-Seq preprocessing. Our goal is to quantify these variances, study their distributions, and understand their statistical implications on downstream modeling. This will include exploring the multitude of decisions researchers face — from quality control to normalization and feature selection — and evaluating how these choices propagate uncertainty through the analysis. Of particular interest is whether variance amplifies due to interactions between decisions made at different stages. By modeling these interactions, we aim to identify cases where suboptimal combinations of preprocessing choices exacerbate variability, potentially distorting biological interpretations. Finally, we will assess various bias correction methods and uncertainty quantification strategies to incorporate into final models. This work aims to provide researchers with actionable insights and robust statistical tools to mitigate preprocessing-induced variance, ultimately enhancing the reliability and reproducibility of RNA-Seq studies.

# Preliminary Results

## Preliminary Methodology Section 

```{r}
#| echo: false
#| align: center
#| label: tbl-1
#| tbl-cap: Basic RNA-Seq Differential Analysis End-to-End Pipeline
table_1 <- data.frame(
    steps = c("1. Pull SRA data from the NIH.",
              "", 
              "2. Compute quality scores.", "", 
              "", 
              "3. Filter low quality reads.", "", 
              "", 
              "4. Trim excess bases.", "", 
              "",
              "5. Align and count genes.",
              "",
              "6. Count normalization.", 
              "", 
              "7. Differential expression analysis."),  
    software = c("prefetch", 
                 "", 
                 "fasterq-dump", "", 
                 "", 
                 "fastp", "", 
                 "", 
                 "fastp", "", 
                 "", 
                 "Various",  
                 "", 
                 "edgeR", 
                 "",
                 "edgeR"), 
    options = c("NA", 
                "", 
                "--skip-technical", "--threads X", 
                "", 
                "--qualified_quality_phred X", "--length_required X", 
                "", 
                "--trim_poly_g", "--trim_ploy_x", 
                "", 
                "Default",  
                "", 
                "calcNormFactors(method='X')", 
                "", 
                "Default"), 
    type = c("NA", 
             "", 
             "Boolean", "Integer", 
             "", 
             "Integer", "Integer", 
             "", 
             "Boolean", "Boolean", 
             "", 
             "Salmon, Kallisto", 
             "", 
             "TMM, RLE, upperquartile",
             "", 
             "NA")
)     

colnames(table_1) <- c("Pipeline Steps", "Software", "Options", "Choices")

table_1 |> kbl(format = "latex", booktabs = T,
     longtable = T, linesep = "")
```

### Statistical Model 

Assume there are $n$ samples of $g$ gene counts. Let $B_g$ denote the count for gene $g$ report to the NIH database, and let $C_{gX}$ denote the count obtained from pipeline with choices $X$. Similar let $D_g$ and $E_{gX}$ denote the p-values obtained from `edgeR`. Now,    
\begin{equation}
    Y_{1X} = \frac 1 g \sum_{i=1}^g (C_{gX} - B_g)^2  
\end{equation}
and 
\begin{equation} 
    Y_{2X} = \frac 1 g \sum_{i=1}^g (E_{gX} - D_g)^2  
\end{equation}
Our primary analysis will focus on the two following regression models: 
\begin{equation}
    Y_{1X_i} = \beta_0 + \sum_{i=1}^p \beta_i X_i + 
        \sum_{1\leq i < j \leq p} \beta_{ij}(X_i \times X_j) + \epsilon
\end{equation}
and 
\begin{equation}
    Y_{2X_i} = \beta_0 + \sum_{i=1}^p \beta_i X_i + 
        \sum_{1\leq i < j \leq p} \beta_{ij}(X_i \times X_j) + \epsilon
\end{equation}
where $p$ is the number of pipeline choices from @tbl-1. The first model studies the effect of each pipeline choice, include all pairwise interactions, on the average square deviation from the official NIH count matrix. The second model does the same, but for the p-values from a differential expression analysis.  

### Simulated Regression Power Analysis 

```{r}
set.seed(33025)

num_predictors <- 50
num_sig_predictors <- 5
alpha <- 0.05
effect_size_mean <- 0.1
effect_size_sd <- 0.05

iter <- 100
sample_sizes <- seq(from = 60, to = 200, by = 10)

simulate_reg <- function(sample_size, num_predictors, num_sig_predictors, 
                           effect_size_mean, effect_size_sd){
    X <- matrix(rnorm(sample_size * num_predictors), 
                      nrow = sample_size, ncol = num_predictors)

    colnames(X) <- paste0("X", 1:num_predictors)

    true_coef <- rnorm(num_sig_predictors, effect_size_mean, effect_size_sd)
    true_coef <- c(true_coef, rep(0, num_predictors - num_sig_predictors)) 

    Y <- X %*% true_coef + rnorm(sample_size)
    data <- data.frame(Y, X)

    lm_fit <- lm(Y ~ X, data = data)
    p_values <- summary(lm_fit)$coefficient[, 4][-1]

    return(p_values)
}

power_reg <- function(sample_sizes, num_predictors, num_sig_predictors, 
                      effect_size_mean, effect_size_sd, iter){
    df <- data.frame()
    for(sample_size in sample_sizes){
        type_2_errors <- 0
        type_1_errors <- 0
        for(i in 1:iter){
            p_values <- simulate_reg(
                sample_size, num_predictors, num_sig_predictors, 
                effect_size_mean, effect_size_sd
            ) 
            type_2_errors <- type_2_errors + 
                sum(p_values[num_sig_predictors] > alpha)
            
            type_1_errors <- type_1_errors + 
                sum(p_values[(num_sig_predictors + 1):num_predictors] < alpha)
        }
        power <- 1 - (type_2_errors / (iter * num_sig_predictors))
        type_1_error_rate <- (
            type_1_errors / (iter * (num_predictors - num_sig_predictors))
        )
        df <- rbind(df, c(sample_size, power, type_1_error_rate))
    }
    colnames(df) <- c("n", "Power", "Type I Error Rate")
    return(df)
}

power_df <- power_reg(sample_sizes, num_predictors, num_sig_predictors, 
          effect_size_mean, effect_size_sd, iter)
```

```{r}
#| fig-cap: Multiple Linear Regression t-test Simulation Based Power Curve
#| fig-align: center
power_df |> ggplot(aes(x = n, y = Power)) + 
            geom_line() + 
            theme_bw()
```

## Quality Score Variance Due to Fasterq-dump Options 

```{r}
#| echo: true
#| eval: false
if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("ShortRead")
BiocManager::install("Rsubread")
```

```{r}
#| echo: true
#| eval: false
library(ShortRead)

sample_1_fq_1 <- readFastq("./data/dump_1/SRR31476642.fastq") 
sample_1_fq_2 <- readFastq("./data/dump_2/SRR31476642.fastq")
sample_1_fq_3 <- readFastq("./data/dump_3/SRR31476642.fastq")
```

```{r}
#| echo: true
#| eval: false
sample_1_fq_1_qual <- as(quality(sample_1_fq_1), "matrix")
sample_1_fq_2_qual <- as(quality(sample_1_fq_2), "matrix")
sample_1_fq_3_qual <- as(quality(sample_1_fq_3), "matrix")

sample_1_fq_13_qual_diff <- sample_1_fq_1_qual - sample_1_fq_3_qual
sample_1_fq_12_qual_diff <- sample_1_fq_1_qual - sample_1_fq_2_qual
```

```{r}
#| echo: true
#| eval: false
mean(sample_1_fq_13_qual_diff)
mean(sample_1_fq_12_qual_diff)
```

## Comparing Alignment Accuracy  

```{r}
#| echo: true
#| eval: false
fastq_files <- list.files(
    path = "./data/dump_1", pattern = "\\.fastq$", full.names = TRUE
)
```

```{r}
#| echo: true
#| eval: false
library(Rsubread)

buildindex(basename="hg19_g1k",
           reference="./data/human_g1k_v37.fasta",
           memory=3600
)

align_reads <- function(file, index_base, output_dir) {
  align(
    index = index_base,
    readfile1 = file,
    output_file = file.path(output_dir, paste0(basename(file), ".bam")),
    nthreads = 4
  )
}
```

```{r}
#| echo: true
#| eval: false
trim_reads <- function(file, quality_threshold = 20, min_length = 30) {
    fq <- readFastq(file)
    fq_filtered <- fq[
        alphabetScore(quality(fq)) >= quality_threshold & width(fq) >= min_length
    ]
    output_file <- sub(".fastq", "_trimmed.fastq", file)
    writeFastq(fq_filtered, output_file, compress = FALSE)
}
```